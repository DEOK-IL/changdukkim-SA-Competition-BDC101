{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"기말고사_ENG_학습코드_model_eng_electra_large.ipynb","provenance":[{"file_id":"1yEdu32Me0ghv5NCRWTIZgR5_h7SLdcFz","timestamp":1607951361717},{"file_id":"1EMzEfTYjYLgEHjCCP1vEr9oOZLXMocGh","timestamp":1606025542423}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"79f1cac56d8f4f6baa4a0d274f196ae1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cb2e175824ec43e8b2c98bbf0d15df13","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_62eac1c293484f6cbd57ae761f0adf23","IPY_MODEL_307b3623bab44a6db37131236b16b5c5"]}},"cb2e175824ec43e8b2c98bbf0d15df13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62eac1c293484f6cbd57ae761f0adf23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a02661237b1b4d1aa82a4a0737b285df","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c1053476d9454dfa9f8c1ec7f7efe502"}},"307b3623bab44a6db37131236b16b5c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_477c83dab50d406f875e26dd6f79761d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 284kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4671fc205fb4255b5b677ac8d05d0fc"}},"a02661237b1b4d1aa82a4a0737b285df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c1053476d9454dfa9f8c1ec7f7efe502":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"477c83dab50d406f875e26dd6f79761d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4671fc205fb4255b5b677ac8d05d0fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"CfPYyPLERU-H"},"source":["# **Preparation**"]},{"cell_type":"markdown","metadata":{"id":"XT4PIM2xRgBp"},"source":["- Edit > Notebook settings > Hardward accelerators > GPU > SAVE\n","- Download the Friends dataset in EmotionLines website:\n","http://doraemon.iis.sinica.edu.tw/emotionlines/download.html\n","- Download the unlabeled json file.\n"]},{"cell_type":"markdown","metadata":{"id":"5NWok7mf5xZk"},"source":["**Settings**"]},{"cell_type":"code","metadata":{"id":"vZewOX-D9BLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608116961812,"user_tz":-540,"elapsed":7729,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"03b2d24a-78cd-49f4-ba27-b5669bd6f46e"},"source":["!pip install transformers --quiet # package installer for python"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4MB 13.3MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 47.5MB/s \n","\u001b[K     |████████████████████████████████| 890kB 50.5MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6idZebToz_Wa"},"source":["import tensorflow as tf\n","import torch\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kjr0jRE4pduK"},"source":["**Dataset 다운로드/전처리**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1StsmWmug94r","executionInfo":{"status":"ok","timestamp":1608116968248,"user_tz":-540,"elapsed":6428,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"c939c9f2-c0ea-4a2a-bd0c-d4eb792fe432"},"source":["#git에 올려둔 friends 데이터셋 받아오기\n","!wget https://raw.githubusercontent.com/changdukkim/changdukkim-SA-Competition-BDC101/master/friends_dev.json\n","!wget https://raw.githubusercontent.com/changdukkim/changdukkim-SA-Competition-BDC101/master/friends_test.json\n","!wget https://raw.githubusercontent.com/changdukkim/changdukkim-SA-Competition-BDC101/master/friends_train.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-12-16 11:09:27--  https://raw.githubusercontent.com/changdukkim/changdukkim-SA-Competition-BDC101/master/friends_dev.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 229392 (224K) [text/plain]\n","Saving to: ‘friends_dev.json.1’\n","\n","\rfriends_dev.json.1    0%[                    ]       0  --.-KB/s               \rfriends_dev.json.1  100%[===================>] 224.02K  --.-KB/s    in 0.01s   \n","\n","2020-12-16 11:09:27 (15.6 MB/s) - ‘friends_dev.json.1’ saved [229392/229392]\n","\n","--2020-12-16 11:09:27--  https://raw.githubusercontent.com/changdukkim/changdukkim-SA-Competition-BDC101/master/friends_test.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 544341 (532K) [text/plain]\n","Saving to: ‘friends_test.json.1’\n","\n","friends_test.json.1 100%[===================>] 531.58K  --.-KB/s    in 0.03s   \n","\n","2020-12-16 11:09:27 (16.2 MB/s) - ‘friends_test.json.1’ saved [544341/544341]\n","\n","--2020-12-16 11:09:27--  https://raw.githubusercontent.com/changdukkim/changdukkim-SA-Competition-BDC101/master/friends_train.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2065470 (2.0M) [text/plain]\n","Saving to: ‘friends_train.json.1’\n","\n","friends_train.json. 100%[===================>]   1.97M  --.-KB/s    in 0.03s   \n","\n","2020-12-16 11:09:27 (69.0 MB/s) - ‘friends_train.json.1’ saved [2065470/2065470]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mwohDzN2amdT"},"source":["#Json 파일을 pandas datatframe으로 변환\n","def jsonToDf(file_name):\n","  with open(file_name, encoding = 'utf-8', mode = 'r') as file:\n","    json_array = json.load(file)\n","  \n","  result = pd.DataFrame.from_dict(json_array[0])\n","\n","  is_first = True\n","  for array in json_array:\n","    if is_first:\n","      is_first = False\n","      continue\n","    \n","    temp_df = pd.DataFrame.from_dict(array)\n","    result = result.append(temp_df, ignore_index = True)\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbmzoqTTbh3X"},"source":["train = jsonToDf('friends_train.json')\n","dev = jsonToDf('friends_dev.json')\n","test = jsonToDf('friends_test.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeHmoVupgtrR","executionInfo":{"status":"ok","timestamp":1608116988779,"user_tz":-540,"elapsed":863,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"2ea2e773-b7b1-485a-da07-c44067a78db7"},"source":["print(train.shape)\n","print(dev.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(10561, 4)\n","(1178, 4)\n","(2764, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BXg643X5hAEG"},"source":["MAX_LEN = 85\n","\n","def getInputsAndLabels(dataset):\n","  data = dataset.copy(deep=True)\n","  #data['utterance'] = data['utterance'].str.lower()\n","\n","  utterances = data['utterance']\n","  utterances = [\"[CLS] \" + str(utterance) + \" [SEP]\" for utterance in utterances]\n","  \n","  encoder = LabelEncoder()\n","  labels = data['emotion'].values\n","  encoder.fit(labels)\n","  labels = encoder.transform(labels)\n","\n","  tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n","  tokenized_texts = [tokenizer.tokenize(utterance) for utterance in utterances]\n","\n","  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","  attention_masks = []\n","  for seq in input_ids:\n","      seq_mask = [float(i>0) for i in seq]\n","      attention_masks.append(seq_mask)\n","\n","  return input_ids, labels, attention_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7c4AgE8PhZjk"},"source":["def getIndex(dataset):\n","  data = dataset.copy(deep = True)\n","  input_index = data.id.tolist()\n","  return torch.tensor(input_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["79f1cac56d8f4f6baa4a0d274f196ae1","cb2e175824ec43e8b2c98bbf0d15df13","62eac1c293484f6cbd57ae761f0adf23","307b3623bab44a6db37131236b16b5c5","a02661237b1b4d1aa82a4a0737b285df","c1053476d9454dfa9f8c1ec7f7efe502","477c83dab50d406f875e26dd6f79761d","d4671fc205fb4255b5b677ac8d05d0fc"]},"id":"6E6xvquPhdz_","executionInfo":{"status":"ok","timestamp":1607955522060,"user_tz":-540,"elapsed":48813,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"d6752dde-6f5c-44ac-f607-cf426decf480"},"source":["train_inputs, train_labels, train_masks = getInputsAndLabels(train)\n","dev_inputs, dev_labels, dev_masks = getInputsAndLabels(dev)\n","test_inputs, test_labels, test_masks = getInputsAndLabels(test)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79f1cac56d8f4f6baa4a0d274f196ae1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MbSh318UhtAN"},"source":["train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","\n","dev_inputs = torch.tensor(dev_inputs)\n","dev_labels = torch.tensor(dev_labels)\n","dev_masks = torch.tensor(dev_masks)\n","\n","test_inputs = torch.tensor(test_inputs)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(test_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I30o8xsah5f4"},"source":["batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","dev_data = TensorDataset(dev_inputs, dev_masks, dev_labels)\n","dev_sampler = SequentialSampler(dev_data)\n","dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=batch_size)\n","\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XwttrxhotgQ","executionInfo":{"status":"ok","timestamp":1607955836034,"user_tz":-540,"elapsed":1794,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"337a6ba9-8ee8-4b99-9930-e79db30f26bf"},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5vg8DYOvjJMy","executionInfo":{"status":"ok","timestamp":1607955848326,"user_tz":-540,"elapsed":4396,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"eaa65f22-4f43-403e-a3c1-c8ce621a3b73"},"source":["model = ElectraForSequenceClassification.from_pretrained('google/electra-large-generator', num_labels=8)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at google/electra-large-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_lm_head.weight', 'generator_lm_head.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-generator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (embeddings_project): Linear(in_features=1024, out_features=256, bias=True)\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=256, out_features=256, bias=True)\n","              (key): Linear(in_features=256, out_features=256, bias=True)\n","              (value): Linear(in_features=256, out_features=256, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=256, out_features=256, bias=True)\n","              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=256, out_features=1024, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=1024, out_features=256, bias=True)\n","            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=256, out_features=256, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=256, out_features=8, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"qpW5i__WjMZA"},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, \n","                  eps = 1e-8\n","                )\n","epochs = 30\n","total_steps = len(train_dataloader) * epochs\n","# 학습률을 조금씩 감소시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-1cVZNC3lavr"},"source":["**Training**"]},{"cell_type":"code","metadata":{"id":"NlyDuh51kXqi"},"source":["from sklearn.metrics import f1_score\n","\n","# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","def getF1Score(preds, labels):\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","\n","  return f1_score(labels_flat, pred_flat, average = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3v731rGdleXV"},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WHcH64rlhA-","executionInfo":{"status":"ok","timestamp":1607957284329,"user_tz":-540,"elapsed":1414420,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"469d5021-82c0-408e-f139-bc4846f62e5a"},"source":["seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","    total_loss = 0\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","             \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    model.eval()\n","    eval_loss, eval_accuracy, eval_f1 = 0, 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in dev_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        with torch.no_grad():     \n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        logits = outputs[0]\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","     \n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        # tmp_eval_f1 = getF1Score(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        # eval_f1 += tmp_eval_f1\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    # print(\"  F1: {0:.2f}\".format(eval_f1/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","\n","  Average training loss: 1.76\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.46\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","\n","  Average training loss: 1.45\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.47\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","\n","  Average training loss: 1.35\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.50\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 30 ========\n","Training...\n","\n","  Average training loss: 1.26\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 5 / 30 ========\n","Training...\n","\n","  Average training loss: 1.19\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 6 / 30 ========\n","Training...\n","\n","  Average training loss: 1.10\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 7 / 30 ========\n","Training...\n","\n","  Average training loss: 1.04\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 8 / 30 ========\n","Training...\n","\n","  Average training loss: 0.97\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 9 / 30 ========\n","Training...\n","\n","  Average training loss: 0.90\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 10 / 30 ========\n","Training...\n","\n","  Average training loss: 0.86\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 11 / 30 ========\n","Training...\n","\n","  Average training loss: 0.81\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 12 / 30 ========\n","Training...\n","\n","  Average training loss: 0.76\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 13 / 30 ========\n","Training...\n","\n","  Average training loss: 0.72\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 14 / 30 ========\n","Training...\n","\n","  Average training loss: 0.68\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 15 / 30 ========\n","Training...\n","\n","  Average training loss: 0.65\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 16 / 30 ========\n","Training...\n","\n","  Average training loss: 0.62\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 17 / 30 ========\n","Training...\n","\n","  Average training loss: 0.59\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 18 / 30 ========\n","Training...\n","\n","  Average training loss: 0.56\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 19 / 30 ========\n","Training...\n","\n","  Average training loss: 0.54\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 20 / 30 ========\n","Training...\n","\n","  Average training loss: 0.52\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 21 / 30 ========\n","Training...\n","\n","  Average training loss: 0.51\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 22 / 30 ========\n","Training...\n","\n","  Average training loss: 0.48\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 23 / 30 ========\n","Training...\n","\n","  Average training loss: 0.47\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 24 / 30 ========\n","Training...\n","\n","  Average training loss: 0.45\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 25 / 30 ========\n","Training...\n","\n","  Average training loss: 0.45\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 26 / 30 ========\n","Training...\n","\n","  Average training loss: 0.43\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 27 / 30 ========\n","Training...\n","\n","  Average training loss: 0.42\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 28 / 30 ========\n","Training...\n","\n","  Average training loss: 0.43\n","  Training epcoh took: 0:00:47\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 29 / 30 ========\n","Training...\n","\n","  Average training loss: 0.41\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 30 / 30 ========\n","Training...\n","\n","  Average training loss: 0.41\n","  Training epcoh took: 0:00:46\n","\n","Running Validation...\n","  Accuracy: 0.54\n","  Validation took: 0:00:01\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zmd0zkpmlrjr","executionInfo":{"status":"ok","timestamp":1607957287969,"user_tz":-540,"elapsed":3618,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"6881deea-399a-4e75-a68c-c6d3ebebc279"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Accuracy: 0.56\n","Test took: 0:00:02\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"_x2olco4mpwj","executionInfo":{"status":"ok","timestamp":1607957288825,"user_tz":-540,"elapsed":4463,"user":{"displayName":"Kevin Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBxSLZnzDuw4LeJY92bMEETdxjrgw3-2jXmLHe8w=s64","userId":"09321854848439482230"}},"outputId":"ad0ff084-25d8-4475-a0b7-e4d5d0ff3a70"},"source":["# 모델 저장\n","torch.save(model.state_dict(), \"model_eng_electra_large.pt\")\n","from google.colab import files\n","files.download('model_eng_electra_large.pt')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_dd142063-a0fa-479b-a930-2ca1b3a9aae6\", \"model_eng_electra_large.pt\", 204440619)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}